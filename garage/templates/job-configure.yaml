{{- if .Values.clusterConfig.enabled -}}
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ include "garage.fullname" . }}-configure
  labels:
    {{- include "garage.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
    "argocd.argoproj.io/hook": PostSync
    "argocd.argoproj.io/hook-delete-policy": BeforeHookCreation,HookSucceeded
spec:
  template:
    metadata:
      labels:
        {{- include "garage.labels" . | nindent 8 }}
      {{- with .Values.clusterConfig.podAnnotations }}
      annotations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
    spec:
      restartPolicy: OnFailure
      serviceAccountName: {{ include "garage.serviceAccountName" . }}
      {{- with .Values.clusterConfig.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      securityContext:
        {{- toYaml .Values.clusterConfig.podSecurityContext | nindent 8 }}
      initContainers:
        - name: get-busybox-tools
          image: busybox:musl
          resources:
            requests:
              cpu: 50m
              memory: 50Mi
            limits:
              cpu: 50m
              memory: 50Mi
          command: ["/bin/sh", "-c", "cp /bin/busybox /tools/busybox && chmod +x /tools/busybox"]
          volumeMounts:
            - name: tools
              mountPath: /tools
        - name: get-garage-bin
          image: "{{ .Values.clusterConfig.image.repository | default .Values.image.repository }}:{{ .Values.clusterConfig.image.tag | default .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.clusterConfig.image.pullPolicy }}
          resources:
            requests:
              cpu: 50m
              memory: 50Mi
            limits:
              cpu: 50m
              memory: 50Mi
          command: ["/tools/busybox", "sh", "-c", "/tools/busybox cp /garage /shared/garage"]
          volumeMounts:
            - name: tools
              mountPath: /tools
            - name: garage-bin
              mountPath: /shared
      containers:
        - name: configure
          image: busybox:latest
          imagePullPolicy: IfNotPresent
          resources:
            {{- toYaml .Values.clusterConfig.resources | nindent 12 }}
          securityContext:
            {{- toYaml .Values.clusterConfig.securityContext | nindent 12 }}
          env:
            - name: GARAGE_RPC_SECRET
              valueFrom:
                secretKeyRef:
                  name: {{ include "garage.secretName" . }}
                  key: rpcSecret
            - name: GARAGE_ADMIN_TOKEN
              valueFrom:
                secretKeyRef:
                  name: {{ include "garage.secretName" . }}
                  key: adminToken
          command: ["/bin/sh", "-c"]
          args:
            - |
              set -e
              
              # Default values
              DEFAULT_ZONE="{{ $.Values.clusterConfig.layout.zone | default "dc1" }}"
              DEFAULT_CAPACITY="{{ $.Values.clusterConfig.layout.capacity | default $.Values.persistence.data.size | default "1T" }}"
              SERVICE_DNS={{ include "garage.fullname" . }}-headless.{{ .Release.Namespace }}.svc.cluster.local

              echo "Waiting for Garage cluster to be ready..."
              sleep 60
              
              # Function to get node ID from metrics
              get_node_id() {
                HOST=$1
                URL="http://$HOST:3903/v2/GetNodeInfo?node=self"
                while true; do
                  # Call the admin API and parse the node ID
                  RESPONSE=$(wget -q -O - \
                    --header "Authorization: Bearer $GARAGE_ADMIN_TOKEN" \
                    "$URL" 2>/dev/null)
                  ID=$(printf '%s' "$RESPONSE" | sed -n -E 's/.*"nodeId":\s*"([a-fA-F0-9]+)".*/\1/p' | head -n 1)

                  if [ -n "$ID" ]; then
                    echo "$ID"
                    return 0
                  fi
                  echo "Waiting for $HOST to be ready..."
                  sleep 5
                done
              }

              # Resolve Coordinator (Node 0)
              COORD_HOST="{{ include "garage.fullname" . }}-0.${SERVICE_DNS}"
              echo "Resolving coordinator $COORD_HOST..."
              COORD_ID=$(get_node_id $COORD_HOST)
              echo "Coordinator ID: $COORD_ID"
              
              GARAGE_RPC_HOST="$COORD_ID@$COORD_HOST:3901"
              
              # Helper function to run garage commands
              run_garage() {
                /shared/garage -h $GARAGE_RPC_HOST "$@"
              }
              
              echo "Garage is ready."

              # Layout configuration
              {{- if .Values.clusterConfig.layout.enabled }}
              echo "Configuring layout..."
              {{- range $i := until (int .Values.deployment.replicaCount) }}
              NODE_HOST="{{ include "garage.fullname" $ }}-{{ $i }}.${SERVICE_DNS}"
              echo "Resolving node $NODE_HOST..."
              NODE_ID=$(get_node_id $NODE_HOST)
              
              run_garage layout assign -z $DEFAULT_ZONE -c $DEFAULT_CAPACITY $NODE_ID || true
              {{- end }}
              
              run_garage layout show
              
              CURRENT_VERSION=$(run_garage layout show | grep "Current cluster layout version" | awk '{print $5}')
              if [ ! -z "$CURRENT_VERSION" ]; then
                 NEXT_VERSION=$((CURRENT_VERSION + 1))
                 echo "Applying layout version $NEXT_VERSION"
                 run_garage layout apply --version $NEXT_VERSION || true
              fi
              {{- end }}

              # Buckets
              {{- range .Values.clusterConfig.buckets }}
              echo "Creating bucket {{ .name }}..."
              run_garage bucket create {{ .name }} 2>/dev/null || true
              {{- if .public }}
              run_garage bucket website --allow {{ .name }} 2>/dev/null || true
              {{- end }}
              {{- end }}

              # Keys
              {{- range .Values.clusterConfig.keys }}
              echo "Importing key {{ .keyId }}..."
              # Validate key ID format (must be GK followed by 24 hex-encoded characters)
              if ! echo "{{ .keyId }}" | grep -qE '^GK[0-9a-fA-F]{24}$'; then
                echo "ERROR: Invalid key ID format: '{{ .keyId }}'. Key ID must start with 'GK' followed by 24 hex characters"
                exit 1
              fi
              # Validate secret key format (must be 64 hex-encoded characters for 32 bytes)
              if ! echo "{{ .secretKey }}" | grep -qE '^[0-9a-fA-F]{64}$'; then
                echo "ERROR: Invalid secret key format. Secret key must be 64 hex characters (32 bytes)"
                exit 1
              fi
              run_garage key import {{ .keyId }} {{ .secretKey }} --yes || true
              {{- if .buckets }}
              {{- $keyId := .keyId }}
              {{- range $bucket := .buckets }}
              run_garage bucket allow {{ $bucket }} --key {{ $keyId }} --read --write || true
              {{- end }}
              {{- end }}
              {{- end }}

              # Extra commands
              {{- range .Values.clusterConfig.extraCommands }}
              echo "Running extra command: {{ . }}"
              run_garage {{ . }}
              {{- end }}

              sleep 3000
          volumeMounts:
            - name: garage-bin
              mountPath: /shared
      volumes:
        - name: tools
          emptyDir: {}
        - name: garage-bin
          emptyDir: {}
      {{- with .Values.clusterConfig.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.clusterConfig.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.clusterConfig.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
{{- end }}
